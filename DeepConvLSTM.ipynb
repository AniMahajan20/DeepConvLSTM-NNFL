{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepConvLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P__1a6Ny-b60",
        "colab_type": "text"
      },
      "source": [
        "#**This file contains the models for all four cases (two each for TASK A and TASK B).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwFQc7vlDHa8",
        "colab_type": "text"
      },
      "source": [
        "Including Relevent Library files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiMgX0XtkESl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f1843ec-bf65-4dc6-8259-7e627868c9ea"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import time\n",
        "import pickle as cp\n",
        "from sliding_window import sliding_window"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8isyaxJCDkY",
        "colab_type": "text"
      },
      "source": [
        "Loading Opportunity Dataset and including accessory files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA3pSs2bjrmb",
        "colab_type": "code",
        "outputId": "e3e660c9-d01a-447a-cdd6-7aef402c289e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "#Loading Opportunity Dataset.\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip --no-check-certificate"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-23 11:07:46--  https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 306636009 (292M) [application/x-httpd-php]\n",
            "Saving to: ‘OpportunityUCIDataset.zip.1’\n",
            "\n",
            "OpportunityUCIDatas 100%[===================>] 292.43M  20.8MB/s    in 15s     \n",
            "\n",
            "2020-05-23 11:08:02 (19.5 MB/s) - ‘OpportunityUCIDataset.zip.1’ saved [306636009/306636009]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPqyTT-ejvhf",
        "colab_type": "code",
        "outputId": "ec945751-9d4f-495e-937c-28021164f790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "#Including preprocessing file.\n",
        "!python preprocess_data.py -h"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: preprocess_data.py [-h] -i INPUT -o OUTPUT [-t {gestures,locomotion}]\n",
            "\n",
            "Preprocess OPPORTUNITY dataset\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -i INPUT, --input INPUT\n",
            "                        OPPORTUNITY zip file\n",
            "  -o OUTPUT, --output OUTPUT\n",
            "                        Processed data file\n",
            "  -t {gestures,locomotion}, --task {gestures,locomotion}\n",
            "                        Type of activities to be recognized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3DZZNRV6kI",
        "colab_type": "text"
      },
      "source": [
        "# TASK A:- Applying Model on Locomotion Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWc-DsGyjqGc",
        "colab_type": "text"
      },
      "source": [
        "**TASK A:- Applying Model on Locomotion Dataset (with NULL class)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6gONmxECbEO",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing the data from data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tdQ-e0wj6lZ",
        "colab_type": "code",
        "outputId": "f74b5e76-44c1-4ca8-f764-a3ff30e4447e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "#Selecting the data relevent to TASK A (Detecting Locomotion).\n",
        "!python preprocess_data.py -i data/OpportunityUCIDataset.zip -o oppChallenge_gestures.data -t locomotion"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking dataset data/OpportunityUCIDataset.zip\n",
            "Processing dataset files ...\n",
            "... file OpportunityUCIDataset/dataset/S1-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL5.dat\n",
            "Final datasets with size: | train (557963, 113) | test (118750, 113) | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NTilB1pkpuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of Sensor Channels used in the OPPORTUNITY dataset.\n",
        "NB_SENSOR_CHANNELS = 113\n",
        "\n",
        "# Number of classes in which data is classified (or to be classified).\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# Length of the sliding window used to segmenting the time-series-data.\n",
        "SLIDING_WINDOW_LENGTH = 24\n",
        "\n",
        "# Length of the input sequence after convolutional operations\n",
        "FINAL_SEQUENCE_LENGTH = 8\n",
        "\n",
        "# Steps of the sliding window used in segmenting the data.\n",
        "SLIDING_WINDOW_STEP = 12\n",
        "\n",
        "# Variable for Batch Size.\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Number filters used in convolutional layers.\n",
        "NUM_FILTERS = 64\n",
        "\n",
        "# Size of filters used in convolutional layers.\n",
        "FILTER_SIZE = 5\n",
        "\n",
        "# Units in the long short-term recurrent layers.\n",
        "NUM_UNITS_LSTM = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqFsHjBqEyFM",
        "colab_type": "text"
      },
      "source": [
        "Loading the data and segmenting it according to length of sliding window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSXuS6IIkYIQ",
        "colab_type": "code",
        "outputId": "a52cee4b-b09f-432c-a363-db23c0506569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "def load_dataset(filename):\n",
        "\n",
        "    f = open(filename, 'rb')\n",
        "    data = cp.load(f)\n",
        "    f.close()\n",
        "\n",
        "    X_train, y_train = data[0]\n",
        "    X_test, y_test = data[1]\n",
        "\n",
        "    print(\" ..from file {}\".format(filename))\n",
        "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
        "\n",
        "    X_train = X_train.astype(np.float32)\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    # The targets are casted to int8 for GPU compatibility.\n",
        "    y_train = y_train.astype(np.uint8)\n",
        "    y_test = y_test.astype(np.uint8)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "print(\"Loading Data...\")\n",
        "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')\n",
        "\n",
        "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
        "def opp_sliding_window(data_x, data_y, ws, ss):\n",
        "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
        "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
        "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
        "\n",
        "# Sensor data is segmented using a sliding window mechanism\n",
        "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
        "\n",
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data...\n",
            " ..from file data/oppChallenge_gestures.data\n",
            " ..reading instances: train (557963, 113), test (118750, 113)\n",
            " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVWw9f7Qkhmi",
        "colab_type": "code",
        "outputId": "30877506-5c7b-4e7c-9917-70ffe435dd7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
        "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))\n",
        "X_train.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 24, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b58G1ZtOkwD0",
        "colab_type": "code",
        "outputId": "5008c303-2fd7-4737-f7ca-92f81ef1945b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 24, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxrOyAsPFbmn",
        "colab_type": "text"
      },
      "source": [
        "Defining DeepConvLSTM Model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohRjr0Skk3Ba",
        "colab_type": "code",
        "outputId": "f760b4ce-da99-4003-a60c-39b37eda8c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1)))\n",
        "\n",
        "#intializing randomly orthogonal weights.\n",
        "initializer = tf.keras.initializers.Orthogonal()\n",
        "\n",
        "#Adding 4 layes of CNN.\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Permute((2,1,3)))\n",
        "model.add(layers.Reshape( (int(model.layers[4].output_shape[1]), int(model.layers[4].output_shape[2]) * int(model.layers[4].output_shape[3]))))\n",
        "\n",
        "#Adding 2 layers of LSTM.\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM,dropout=0.5,return_sequences=True,kernel_initializer=initializer))\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM,dropout=0.5,return_sequences=True,kernel_initializer=initializer))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Applying dense layer of Softmax to the output of 4-CNN layers and 2 LSTM layers.\n",
        "model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "    \n",
        "#Printing Summery of Model.\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 20, 113, 64)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 12, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 113, 64)        20544     \n",
            "_________________________________________________________________\n",
            "permute_2 (Permute)          (None, 113, 8, 64)        0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 113, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 113, 128)          328192    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 113, 128)          131584    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 14464)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 72325     \n",
            "=================================================================\n",
            "Total params: 594,117\n",
            "Trainable params: 594,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCaxEahNk88o",
        "colab_type": "code",
        "outputId": "b9213c71-1050-41d2-87b5-342082632c25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.layers[4].output_shape\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 113, 8, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoRj4zqlGgl7",
        "colab_type": "text"
      },
      "source": [
        "Encoding the training and testing data to One-Hot Encoded form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pv5M6pklGIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tohe = OneHotEncoder()\n",
        "\tohe.fit(y_train)\n",
        "\ty_train_enc = ohe.transform(y_train)\n",
        "\ty_test_enc = ohe.transform(y_test)\n",
        "\treturn y_train_enc.A, y_test_enc.A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeQCYAZLlLft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=y_train.reshape(-1,1)\n",
        "y_test=y_test.reshape(-1,1)\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ACY8DbGvQW",
        "colab_type": "text"
      },
      "source": [
        "Compiling Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQowU-xPlQM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYRICqa_lZmu",
        "colab_type": "code",
        "outputId": "327e13bf-d307-4c4c-fb71-a80e0ff960fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRmYyNjHPZj_",
        "colab_type": "text"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAnQUG9ZlnWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit(X_train, y_train_enc, batch_size=BATCH_SIZE, epochs=50,validation_split=0.1)\n",
        "\n",
        "#The model is already trained using above statement and trained model is loaded for testing data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmdiSdF68eS",
        "colab_type": "text"
      },
      "source": [
        "Load Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5DWzurF06571",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model1 = load_model('task_a_with_null_working.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaiUQVqjG50-",
        "colab_type": "text"
      },
      "source": [
        "Testing our Model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZUQTOKFmfeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob = new_model1.predict(X_test) \n",
        "y_classes = y_prob.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwtdGBcsHHK2",
        "colab_type": "text"
      },
      "source": [
        "Printing F1 Score and relevent Result Metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdhNrWVanQC-",
        "colab_type": "code",
        "outputId": "aa6b4c6b-db90-4061-d717-32c90455c853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "precision, recall, f1_score, supp = precision_recall_fscore_support(y_classes, y_test, average='micro')\n",
        "\n",
        "\n",
        "print(confusion_matrix(y_classes, y_test))\n",
        "print(\"PRECISION: {0}\" .format(precision))\n",
        "print(\"RECALL: {0}\".format(recall))\n",
        "print(\"F1_SCORE : {0}\".format(f1_score))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1531   20  107   18   11]\n",
            " [ 226 2917  441   25    1]\n",
            " [ 252  134 1719    0    0]\n",
            " [  28   30    5 1969   16]\n",
            " [   5    0    0    4  435]]\n",
            "PRECISION: 0.8662825955124318\n",
            "RECALL: 0.8662825955124318\n",
            "F1_SCORE : 0.8662825955124317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IplID-c2omqM",
        "colab_type": "text"
      },
      "source": [
        "**Task A:- Applying Model on Locomotion Dataset (Without NULL class)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ej0jl0FMSKuR"
      },
      "source": [
        "Preprocessing the data from data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlXNF1ua4KHT",
        "colab_type": "code",
        "outputId": "f79d8e61-5459-4a3f-ca5e-02f0556d9d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "!python preprocess_data.py -i data/OpportunityUCIDataset.zip -o oppChallenge_gestures.data -t locomotion"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking dataset data/OpportunityUCIDataset.zip\n",
            "Processing dataset files ...\n",
            "... file OpportunityUCIDataset/dataset/S1-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL5.dat\n",
            "Final datasets with size: | train (557963, 113) | test (118750, 113) | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3efSq7M6Wrhu",
        "colab_type": "text"
      },
      "source": [
        "Defining important variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYGa0dayncU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variable for Number of sensor channels in the OPPORTUNITY dataset.\n",
        "NB_SENSOR_CHANNELS = 113\n",
        "\n",
        "# Variable for number of classes in which data is classified (or to be classified). \n",
        "NUM_CLASSES = 4\n",
        "\n",
        "# Variable for length of the sliding window used in segmenting the time-series-data.\n",
        "SLIDING_WINDOW_LENGTH = 24\n",
        "\n",
        "# Length of the input sequence after convolutional operations\n",
        "FINAL_SEQUENCE_LENGTH = 8\n",
        "\n",
        "# Variable for steps of the sliding window used in segmenting the data\n",
        "SLIDING_WINDOW_STEP = 12\n",
        "\n",
        "# Variable for Batch Size\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Number filters used in convolutional layers\n",
        "NUM_FILTERS = 64\n",
        "\n",
        "# Size of each filter convolutional layers\n",
        "FILTER_SIZE = 5\n",
        "\n",
        "# Number of unit in the LSTM layer.\n",
        "NUM_UNITS_LSTM = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r17iy-P9VLdH",
        "colab_type": "text"
      },
      "source": [
        "Loading Data an segmenting data according to sliding window length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS3XcPKKozqU",
        "colab_type": "code",
        "outputId": "23ffeb5f-b835-4b97-c7bc-045527e4fe7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "def load_dataset(filename):\n",
        "\n",
        "    f = open(filename, 'rb')\n",
        "    data = cp.load(f)\n",
        "    f.close()\n",
        "\n",
        "    X_train, y_train = data[0]\n",
        "    X_test, y_test = data[1]\n",
        "\n",
        "    print(\" ..from file {}\".format(filename))\n",
        "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
        "\n",
        "    X_train = X_train.astype(np.float32)\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    # The targets are casted to int8 for GPU compatibility.\n",
        "    y_train = y_train.astype(np.uint8)\n",
        "    y_test = y_test.astype(np.uint8)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "print(\"Loading data...\")\n",
        "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')\n",
        "\n",
        "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
        "def opp_sliding_window(data_x, data_y, ws, ss):\n",
        "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
        "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
        "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
        "\n",
        "# Sensor data is segmented using a sliding window mechanism\n",
        "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
        "\n",
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            " ..from file data/oppChallenge_gestures.data\n",
            " ..reading instances: train (557963, 113), test (118750, 113)\n",
            " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBfB1OQLo-tK",
        "colab_type": "code",
        "outputId": "18e879ae-dc71-40ce-fc3a-0eb20a703417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
        "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n",
            "(46495, 24, 113, 1)\n",
            "(46495,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1xewq4kVkC9",
        "colab_type": "text"
      },
      "source": [
        "Defining Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJM1D0LSpDiC",
        "colab_type": "code",
        "outputId": "0cb520de-e8f9-4ef9-b319-f6aa41be486e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1)))\n",
        "\n",
        "# intializing randomly orthogonal weights.\n",
        "initializer = tf.keras.initializers.Orthogonal()\n",
        "\n",
        "# Adding 4 layers of CNN\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Permute((2,1,3)))\n",
        "model.add(layers.Reshape( (int(model.layers[4].output_shape[1]), int(model.layers[4].output_shape[2]) * int(model.layers[4].output_shape[3]))))\n",
        "\n",
        "# Adding 2 layers of LSTM.\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Adding a dense layer of softmax.\n",
        "model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "\n",
        "# Printing Model Summary.\n",
        "model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 20, 113, 64)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 12, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 113, 64)        20544     \n",
            "_________________________________________________________________\n",
            "permute_3 (Permute)          (None, 113, 8, 64)        0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 113, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 113, 128)          328192    \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 113, 128)          131584    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 14464)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 57860     \n",
            "=================================================================\n",
            "Total params: 579,652\n",
            "Trainable params: 579,652\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0khRszPUX2v7"
      },
      "source": [
        "Encoding the training and testing data to One-Hot Encoded form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaZKpUJrpKNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tohe = OneHotEncoder()\n",
        "\tohe.fit(y_train)\n",
        "\ty_train_enc = ohe.transform(y_train)\n",
        "\ty_test_enc = ohe.transform(y_test)\n",
        "\treturn y_train_enc.A, y_test_enc.A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pb_3vwfZFwV",
        "colab_type": "text"
      },
      "source": [
        "Removing NULL class values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl9W1HBFpPY-",
        "colab_type": "code",
        "outputId": "4ed55f17-ea88-488b-dbeb-be88a596ae47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "y_train=y_train.reshape(-1,1)\n",
        "y_test=y_test.reshape(-1,1)\n",
        "\n",
        "count = 0\n",
        "idx = []\n",
        "for i in range(0,y_train.shape[0]):\n",
        "  if(y_train[i] == 0):\n",
        "    count += 1\n",
        "    idx.append(i)\n",
        "print(len(idx))\n",
        "y_train_new = np.delete(y_train,idx)\n",
        "y_train_new = y_train_new.reshape(-1,1)\n",
        "print(y_train_new.shape)\n",
        "\n",
        "print(X_train.shape)\n",
        "X_train_new = np.delete(X_train,idx,axis=0)\n",
        "print(X_train_new.shape)\n",
        "\n",
        "count = 0\n",
        "idx = []\n",
        "for i in range(0,y_test.shape[0]):\n",
        "  if(y_test[i] == 0):\n",
        "    count += 1\n",
        "    idx.append(i)\n",
        "print(len(idx))\n",
        "y_test_new = np.delete(y_test,idx,axis = 0)\n",
        "print(y_test_new.shape)\n",
        "\n",
        "X_test_new = np.delete(X_test,idx,axis = 0)\n",
        "print(X_test_new.shape)\n",
        "\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train_new, y_test_new)\n",
        "print(y_train_enc.shape)\n",
        "print(y_test_enc.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7680\n",
            "(38815, 1)\n",
            "(46495, 24, 113, 1)\n",
            "(38815, 24, 113, 1)\n",
            "2042\n",
            "(7852, 1)\n",
            "(7852, 24, 113, 1)\n",
            "(38815, 4)\n",
            "(7852, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx70Nbg9wOJ4",
        "colab_type": "code",
        "outputId": "d7935045-aba2-4798-fddd-16cc4351046f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "y_train_enc"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xVHF9bRiX2v9"
      },
      "source": [
        "Compiling Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxBI7DW1pTIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og3Anc-rppMK",
        "colab_type": "code",
        "outputId": "d132ee65-e729-4580-e9d7-d8a1443e6f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 24, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7wtOUCvPX2v9"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heym0oFhpY9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit(X_train_new, y_train_enc, batch_size=BATCH_SIZE, epochs=50,validation_split=0.1)\n",
        "\n",
        "#Model is already trained using above lines of code and loaded directly for testing purposes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-QfbD0M4AbY",
        "colab_type": "text"
      },
      "source": [
        "Loading Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gI1mVQeO3-uH",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model2 = load_model('task_a_without_null_working.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mx2MlezLX2v9"
      },
      "source": [
        "Testing our Model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMjrtWeHpdNE",
        "colab_type": "code",
        "outputId": "ff5b887e-0c5e-499a-b8f3-6d5bc2ceb5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_prob = new_model2.predict(X_test_new) \n",
        "#print(y_prob)\n",
        "\n",
        "#adjusting format of output to the required format of result.\n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "\n",
        "for i in range(0,y_classes.shape[0]):\n",
        "  y_classes[i] += 1\n",
        "print(np.sum(y_classes))\n",
        "print(np.sum(y_test_new))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15400\n",
            "15545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEQnA6BNuN_6",
        "colab_type": "code",
        "outputId": "8d24d2e1-e94b-42a6-e4dc-57fb70805002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_prob.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7852, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kD4UpJ0RX2v-"
      },
      "source": [
        "Printing F1 Score and relevent Result Metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKqsOIBwucAK",
        "colab_type": "code",
        "outputId": "c74b658c-b730-4d4d-e67b-2f56dc1c9d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1_score, supp = precision_recall_fscore_support(y_test_new,y_classes,average='weighted')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_classes, y_test_new))\n",
        "#print(metrics)\n",
        "print(\"PRECISION: {0}\" .format(precision))\n",
        "print(\"RECALL: {0}\".format(recall))\n",
        "print(\"F1_SCORE : {0}\".format(f1_score))\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2853  322   43    1]\n",
            " [ 223 1948    5    3]\n",
            " [  25    2 1963    3]\n",
            " [   0    0    5  456]]\n",
            "PRECISION: 0.919917164493682\n",
            "RECALL: 0.9195109526235354\n",
            "F1_SCORE : 0.9194705489636714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cbj_YH-ZX68",
        "colab_type": "text"
      },
      "source": [
        "**----------------------------------------------------------------------------------------------------------------------------------------------------------------**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni0DrRxrZMH8",
        "colab_type": "text"
      },
      "source": [
        "# TASK B:- Applying Model on Gestures Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuxgJZMy9q-1",
        "colab_type": "text"
      },
      "source": [
        "**TASK B :- Applying Model on Gestures (with NULL Class)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8X8w_bePdVKl"
      },
      "source": [
        "Preprocessing the data from data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Plu9za-rbAq",
        "colab_type": "code",
        "outputId": "1b4bc140-5011-4edd-cc01-5b9e839a32f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "!python preprocess_data.py -i data/OpportunityUCIDataset.zip -o oppChallenge_gestures.data -t gestures"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking dataset data/OpportunityUCIDataset.zip\n",
            "Processing dataset files ...\n",
            "... file OpportunityUCIDataset/dataset/S1-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL5.dat\n",
            "Final datasets with size: | train (557963, 113) | test (118750, 113) | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAPgfCuzry_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hardcoded number of sensor channels employed in the OPPORTUNITY challenge\n",
        "NB_SENSOR_CHANNELS = 113\n",
        "\n",
        "# Hardcoded number of classes in the gesture recognition problem\n",
        "NUM_CLASSES = 18\n",
        "\n",
        "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
        "SLIDING_WINDOW_LENGTH = 24\n",
        "\n",
        "# Length of the input sequence after convolutional operations\n",
        "FINAL_SEQUENCE_LENGTH = 8\n",
        "\n",
        "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
        "SLIDING_WINDOW_STEP = 12\n",
        "\n",
        "# Batch Size\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Number filters convolutional layers\n",
        "NUM_FILTERS = 64\n",
        "\n",
        "# Size filters convolutional layers\n",
        "FILTER_SIZE = 5\n",
        "\n",
        "# Number of unit in the long short-term recurrent layers\n",
        "NUM_UNITS_LSTM = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yGkixGUydVKm"
      },
      "source": [
        "Loading the data and segmenting it according to length of sliding window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w5kuIMDr5Qb",
        "colab_type": "code",
        "outputId": "5150095c-7748-47eb-c46d-40e87c4e78c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "def load_dataset(filename):\n",
        "\n",
        "    f = open(filename, 'rb')\n",
        "    data = cp.load(f)\n",
        "    f.close()\n",
        "\n",
        "    X_train, y_train = data[0]\n",
        "    X_test, y_test = data[1]\n",
        "\n",
        "    print(\" ..from file {}\".format(filename))\n",
        "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
        "\n",
        "    X_train = X_train.astype(np.float32)\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    # The targets are casted to int8 for GPU compatibility.\n",
        "    y_train = y_train.astype(np.uint8)\n",
        "    y_test = y_test.astype(np.uint8)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "print(\"Loading data...\")\n",
        "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')\n",
        "\n",
        "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
        "def opp_sliding_window(data_x, data_y, ws, ss):\n",
        "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
        "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
        "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
        "\n",
        "# Sensor data is segmented using a sliding window mechanism\n",
        "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
        "\n",
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            " ..from file data/oppChallenge_gestures.data\n",
            " ..reading instances: train (557963, 113), test (118750, 113)\n",
            " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5_HUMPVr_aJ",
        "colab_type": "code",
        "outputId": "fa0fbd1e-38d2-412e-fc29-facd9743fd53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
        "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))\n",
        "X_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 24, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA_Z98xG8Qdp",
        "colab_type": "code",
        "outputId": "47f59fe0-ee1e-46b3-c8e2-9e52d1c724dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 24, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pu94WSCAdVKm"
      },
      "source": [
        "Defining DeepConvLSTM Model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGj-7dtQsPLz",
        "colab_type": "code",
        "outputId": "fcb73dc6-1bd2-492a-b9d8-a30acd036e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1)))\n",
        "initializer = tf.keras.initializers.Orthogonal()\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Permute((2,1,3)))\n",
        "model.add(layers.Reshape( (int(model.layers[4].output_shape[1]), int(model.layers[4].output_shape[2]) * int(model.layers[4].output_shape[3]))))\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM,return_sequences=True))\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM,return_sequences=True))\n",
        "#model.add(layers.Reshape( (-1, NUM_UNITS_LSTM)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "\n",
        "    \n",
        "#Printing Model Summary.\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 20, 113, 64)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 113, 64)        20544     \n",
            "_________________________________________________________________\n",
            "permute (Permute)            (None, 113, 8, 64)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 113, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 113, 128)          328192    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 113, 128)          131584    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 14464)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 18)                260370    \n",
            "=================================================================\n",
            "Total params: 782,162\n",
            "Trainable params: 782,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaNO5DoDt_MH",
        "colab_type": "code",
        "outputId": "278ceabd-73c7-4d6d-cc18-38fbe639ee98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.layers[4].output_shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 113, 8, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j0WHzEx5dVKn"
      },
      "source": [
        "Encoding the training and testing data to One-Hot Encoded form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp5zuMCyBJ7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tohe = OneHotEncoder()\n",
        "\tohe.fit(y_train)\n",
        "\ty_train_enc = ohe.transform(y_train)\n",
        "\ty_test_enc = ohe.transform(y_test)\n",
        "\treturn y_train_enc.A, y_test_enc.A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbmz5JJyBNAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=y_train.reshape(-1,1)\n",
        "y_test=y_test.reshape(-1,1)\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ybj5zXlidVKn"
      },
      "source": [
        "Compiling Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNAA6mqD12N7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sd6ubHccdVKn"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0pRaMrtxOe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit(X_train, y_train_enc, batch_size=BATCH_SIZE, epochs=50,validation_split=0.1)\n",
        "\n",
        "#Model is already trained and loaded directly for testing data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADanzBQu17f2",
        "colab_type": "code",
        "outputId": "a6c8ed4f-fb5c-44e9-d11b-05bd9185bcd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8QPdSDKJzoHK",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model3 = load_model('task_b_with_null_working.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mwBKaGsadVKo"
      },
      "source": [
        "Testing our Model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRxKgwvID5nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob = new_model3.predict(X_test) \n",
        "y_classes = y_prob.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lvn7o8oNfb9",
        "colab_type": "code",
        "outputId": "03ecbbb3-8bcb-4ef8-caf9-010b680745d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y_classes.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9894,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GRrXzA36dVKo"
      },
      "source": [
        "Printing F1 Score and relevent Result Metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_z9Q-FJawlW",
        "colab_type": "code",
        "outputId": "62fa1bea-d049-46fb-ad52-3d883f61edf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1_score, supp = precision_recall_fscore_support(y_classes, y_test, average='weighted')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_classes, y_test))\n",
        "#print(metrics)\n",
        "#print(\"PRECISION: {0}\" .format(precision))\n",
        "#print(\"RECALL: {0}\".format(recall))\n",
        "print(\"F1_SCORE : {0}\".format(f1_score))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7918   11   16    6   11  112   40   40   44   11   29   21    6   16\n",
            "    12   64  169   34]\n",
            " [  11   28    0    8    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]\n",
            " [   9    0   54    0    3    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]\n",
            " [  26   19    2   46    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    1    0]\n",
            " [   4    0   23    0   69    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]\n",
            " [  18    0    0    0    0  105    9    2    0    0    0    0    0    0\n",
            "     0    0    0    0]\n",
            " [  13    0    0    0    0    5  104    0    0    0    0    0    0    0\n",
            "     1    0    0    0]\n",
            " [  21    0    0    0    0    5    0   49    8    0    0    1    0    0\n",
            "     0    0    3    0]\n",
            " [  17    0    0    0    0    0    3    3   22    0    0    0    0    0\n",
            "     0    0    1    0]\n",
            " [   8    0    0    0    0    0    1    1    0   21    3    7    6    2\n",
            "     0    0    0   14]\n",
            " [   6    0    0    0    0    0    3    0    0    2    8    3    3    0\n",
            "     0    0    0    0]\n",
            " [   4    0    0    0    0    0    0    1    0    1    0    1    0    5\n",
            "     1    0    0    0]\n",
            " [   2    0    0    0    0    0    0    0    2    1    2    3    6    2\n",
            "     7    0    0    0]\n",
            " [  90    0    0    0    0    0    0    3    1    0    0    4    3   34\n",
            "     9    0    0    0]\n",
            " [  10    0    0    0    0    0    0    1    0    1    0    0    2    8\n",
            "    31    0    0    0]\n",
            " [   2    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0   35    1    0]\n",
            " [  70    0    0    0    0    0    0    0    0    1    0    0    0    0\n",
            "     0    0  142    0]\n",
            " [   8    0    0    0    0    1    0    0    0    1    0    0    0    0\n",
            "     0    0    0   57]]\n",
            "PRECISION: 0.9023661780774751\n",
            "RECALL: 0.8823529411764706\n",
            "F1_SCORE : 0.8885616449973379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su3kgv8P7O-s",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF1aPhR9-MxK",
        "colab_type": "text"
      },
      "source": [
        "**TASK B:- Applying Model on Gesture dataset (without NULL class)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BZ_N6_JdvZGA"
      },
      "source": [
        "Preprocessing the data from data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7db4fd0e-95f1-479a-bd91-baecb98e31cb",
        "id": "U-LM-FdT_j5-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "!python preprocess_data.py -i data/OpportunityUCIDataset.zip -o oppChallenge_gestures.data -t gestures"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking dataset data/OpportunityUCIDataset.zip\n",
            "Processing dataset files ...\n",
            "... file OpportunityUCIDataset/dataset/S1-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL5.dat\n",
            "Final datasets with size: | train (557963, 113) | test (118750, 113) | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TiV1FCtGvZGF"
      },
      "source": [
        "Defining important variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VXZPyTBA_j6B",
        "colab": {}
      },
      "source": [
        "# Hardcoded number of sensor channels employed in the OPPORTUNITY challenge\n",
        "NB_SENSOR_CHANNELS = 113\n",
        "\n",
        "# Hardcoded number of classes in the gesture recognition problem\n",
        "NUM_CLASSES = 17\n",
        "\n",
        "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
        "SLIDING_WINDOW_LENGTH = 24\n",
        "\n",
        "# Length of the input sequence after convolutional operations\n",
        "FINAL_SEQUENCE_LENGTH = 8\n",
        "\n",
        "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
        "SLIDING_WINDOW_STEP = 12\n",
        "\n",
        "# Batch Size\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Number filters convolutional layers\n",
        "NUM_FILTERS = 64\n",
        "\n",
        "# Size filters convolutional layers\n",
        "FILTER_SIZE = 5\n",
        "\n",
        "# Number of unit in the long short-term recurrent layers\n",
        "NUM_UNITS_LSTM = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Szp6GpLQvZGF"
      },
      "source": [
        "Loading Data an segmenting data according to sliding window length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "03f758b8-2a00-42d7-a449-31aff4040c8a",
        "id": "zWdSB-OY_j6D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "def load_dataset(filename):\n",
        "\n",
        "    f = open(filename, 'rb')\n",
        "    data = cp.load(f)\n",
        "    f.close()\n",
        "\n",
        "    X_train, y_train = data[0]\n",
        "    X_test, y_test = data[1]\n",
        "\n",
        "    print(\" ..from file {}\".format(filename))\n",
        "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
        "\n",
        "    X_train = X_train.astype(np.float32)\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    # The targets are casted to int8 for GPU compatibility.\n",
        "    y_train = y_train.astype(np.uint8)\n",
        "    y_test = y_test.astype(np.uint8)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "print(\"Loading data...\")\n",
        "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')\n",
        "\n",
        "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
        "def opp_sliding_window(data_x, data_y, ws, ss):\n",
        "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
        "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
        "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
        "\n",
        "# Sensor data is segmented using a sliding window mechanism\n",
        "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
        "\n",
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            " ..from file data/oppChallenge_gestures.data\n",
            " ..reading instances: train (557963, 113), test (118750, 113)\n",
            " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "976362af-9a20-4126-ae7e-b7f2cca9de2c",
        "id": "kUBIE2oy_j6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
        "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n",
            "(46495, 24, 113, 1)\n",
            "(46495,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ndFVBBW8vZGG"
      },
      "source": [
        "Defining DeepConvLSTM Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lad-1b646NPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "bc286206-ffc4-4e0c-a72c-e012c96d0c7f"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1)))\n",
        "\n",
        "#intializing weights\n",
        "initializer = tf.keras.initializers.Orthogonal()\n",
        "\n",
        "#Adding 4 CNN layers.\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Permute((2,1,3)))\n",
        "model.add(layers.Reshape( (int(model.layers[4].output_shape[1]), int(model.layers[4].output_shape[2]) * int(model.layers[4].output_shape[3]))))\n",
        "\n",
        "#Adding 2 LSTM layers.\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "#model.add(layers.Reshape( (-1, NUM_UNITS_LSTM)))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Applying a dense layer of softmax.\n",
        "model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 20, 113, 64)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 113, 64)        20544     \n",
            "_________________________________________________________________\n",
            "permute_1 (Permute)          (None, 113, 8, 64)        0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 113, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 113, 128)          328192    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 113, 128)          131584    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 14464)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 17)                245905    \n",
            "=================================================================\n",
            "Total params: 767,697\n",
            "Trainable params: 767,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TK6tDq7l_j6L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "721ad297-77be-4c33-9d46-71965ccdebf0"
      },
      "source": [
        "model.layers[4].output_shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 113, 8, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JCAhtKnavZGH"
      },
      "source": [
        "Encoding the training and testing data to One-Hot Encoded form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "11MzIEYv_j6O",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tohe = OneHotEncoder()\n",
        "\tohe.fit(y_train)\n",
        "\ty_train_enc = ohe.transform(y_train)\n",
        "\ty_test_enc = ohe.transform(y_test)\n",
        "\treturn y_train_enc.A, y_test_enc.A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nwD3_RgPvZGH"
      },
      "source": [
        "Removing NULL class values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F7RnOi_t_j6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "6c52cbe5-62c4-4fe4-de6f-fe94b15b4ad3"
      },
      "source": [
        "y_train=y_train.reshape(-1,1)\n",
        "y_test=y_test.reshape(-1,1)\n",
        "\n",
        "count = 0\n",
        "idx = []\n",
        "for i in range(0,y_train.shape[0]):\n",
        "  if(y_train[i] == 0):\n",
        "    count += 1\n",
        "    idx.append(i)\n",
        "print(len(idx))\n",
        "y_train_new = np.delete(y_train,idx)\n",
        "y_train_new = y_train_new.reshape(-1,1)\n",
        "print(y_train_new.shape)\n",
        "\n",
        "print(X_train.shape)\n",
        "X_train_new = np.delete(X_train,idx,axis=0)\n",
        "print(X_train_new.shape)\n",
        "\n",
        "count = 0\n",
        "idx = []\n",
        "for i in range(0,y_test.shape[0]):\n",
        "  if(y_test[i] == 0):\n",
        "    count += 1\n",
        "    idx.append(i)\n",
        "print(len(idx))\n",
        "y_test_new = np.delete(y_test,idx,axis = 0)\n",
        "print(y_test_new.shape)\n",
        "\n",
        "X_test_new = np.delete(X_test,idx,axis = 0)\n",
        "print(X_test_new.shape)\n",
        "\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train_new, y_test_new)\n",
        "print(y_train_enc.shape)\n",
        "print(y_test_enc.shape)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32348\n",
            "(14147, 1)\n",
            "(46495, 24, 113, 1)\n",
            "(14147, 24, 113, 1)\n",
            "8237\n",
            "(1657, 1)\n",
            "(1657, 24, 113, 1)\n",
            "(14147, 17)\n",
            "(1657, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Lim-F7XvZGI"
      },
      "source": [
        "Compiling Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmssHLLhZGZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oCVjrd58vZGI"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H13q5gXE_j6T",
        "colab": {}
      },
      "source": [
        "#model.fit(X_train_new, y_train_enc, batch_size=BATCH_SIZE, epochs=500,validation_split=0.1)\n",
        "\n",
        "#Model is already trained and loaded for testing directly."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaDLRP9AvvHI",
        "colab_type": "text"
      },
      "source": [
        "Loading Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZgXt-sRDcK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model4 = load_model('task_b_without_null_working.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1R9JhWEavZGI"
      },
      "source": [
        "Testing our Model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbOVz8AEGDEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob = new_model4.predict(X_test_new) \n",
        "#print(y_prob)\n",
        "\n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "for i in range(0,y_classes.shape[0]):\n",
        "  y_classes[i] += 1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "srqeq-yjvZGJ"
      },
      "source": [
        "Printing F1 Score and relevent Result Metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCqVwXn8GUXm",
        "colab_type": "code",
        "outputId": "b5e5a0c2-7c1e-4f54-f740-3c31936731eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1_score, supp = precision_recall_fscore_support(y_classes, y_test_new, average='micro')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_classes, y_test_new))\n",
        "#print(metrics)\n",
        "print(\"PRECISION: {0}\" .format(precision))\n",
        "print(\"RECALL: {0}\".format(recall))\n",
        "print(\"F1_SCORE : {0}\".format(f1_score))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 50   0   3   0   0   0   0   0   0   0   0   0   0   0   0   4   0]\n",
            " [  0  72   0   2   1   0   0   0   0   0   0   0   0   0   0   4   0]\n",
            " [  8   2  57   1   0   0   0   0   0   0   0   0   0   0   1   6   0]\n",
            " [  0  21   0  80   0   0   0   0   1   0   0   0   0   0   2   2   0]\n",
            " [  0   0   0   0 199  12  10   2   0   0   2   1   1   0   4   5   0]\n",
            " [  0   0   0   0   2 125   1   1   0   0   0   0   1   0   0   7   0]\n",
            " [  0   0   0   0   9   4  82   6   2   0   1   1   0   0   0  13   0]\n",
            " [  0   0   0   0  14  15   3  65   0   1   2   0   1   0   1   6   0]\n",
            " [  0   0   0   0   0   2   1   0  32   5   5   3   1   0   0   4   0]\n",
            " [  0   0   0   0   2   2   0   0   2  34   0   1   0   0   0   4   0]\n",
            " [  0   0   0   0   1   0   1   2   1   0  25   4   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   1   0   1   3  15   2   2   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0   1   0   2   0  60  11   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   1  48   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  87   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3 260   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1 105]]\n",
            "PRECISION: 0.8424864212432106\n",
            "RECALL: 0.8424864212432106\n",
            "F1_SCORE : 0.8424864212432107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA_TOfIQ6giH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}